import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler, LabelEncoder
from sklearn.model_selection import train_test_split
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset

# Load the CSV data (replace 'traffic.csv' with your file path)
df = pd.read_csv('traffic.csv')

# Parse DateTime
df['DateTime'] = pd.to_datetime(df['DateTime'])

# Feature engineering
df['hour'] = df['DateTime'].dt.hour
df['day_of_week'] = df['DateTime'].dt.dayofweek
df['month'] = df['DateTime'].dt.month
df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)

# Encode Junction
le_junction = LabelEncoder()
df['junction_encoded'] = le_junction.fit_transform(df['Junction'])

# Normalize ID (target variable)
scaler = MinMaxScaler()
df['id_scaled'] = scaler.fit_transform(df[['ID']])

# Prepare features and target
features = ['junction_encoded', 'hour', 'day_of_week', 'month', 'is_weekend']
target = 'id_scaled'

# Create sequences for time-series prediction (past 24 hours to predict next hour)
def create_sequences(data, seq_length=24):
    xs = []
    ys = []
    for junction in data['Junction'].unique():
        junction_data = data[data['Junction'] == junction].sort_values('DateTime')
        junction_array = junction_data[features + [target]].values
        for i in range(len(junction_data) - seq_length):
            xs.append(junction_array[i:i + seq_length, :-1])  # Features
            ys.append(junction_array[i + seq_length, -1])  # Target
    return np.array(xs), np.array(ys)

seq_length = 24
X, y = create_sequences(df, seq_length)

# Split into train/test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Convert to PyTorch tensors
X_train = torch.tensor(X_train, dtype=torch.float32)
y_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)
X_test = torch.tensor(X_test, dtype=torch.float32)
y_test = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)

# DataLoader
train_data = TensorDataset(X_train, y_train)
train_loader = DataLoader(train_data, batch_size=64, shuffle=True)

# LSTM Model
class TrafficLSTM(nn.Module):
    def __init__(self, input_size, hidden_size=50, num_layers=2):
        super().__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, 1)
    
    def forward(self, x):
        out, _ = self.lstm(x)
        out = self.fc(out[:, -1, :])  # Last timestep
        return out

input_size = X_train.shape[2]  # Number of features
model = TrafficLSTM(input_size)

# Loss and optimizer
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# Training loop
epochs = 50
for epoch in range(epochs):
    model.train()
    for batch_x, batch_y in train_loader:
        optimizer.zero_grad()
        outputs = model(batch_x)
        loss = criterion(outputs, batch_y)
        loss.backward()
        optimizer.step()
    if (epoch + 1) % 10 == 0:
        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')

# Evaluation
model.eval()
with torch.no_grad():
    predictions = model(X_test)
    test_loss = criterion(predictions, y_test)
    print(f'Test MSE Loss: {test_loss.item():.4f}')

# Inverse transform predictions to original scale
predictions = scaler.inverse_transform(predictions.numpy())
y_test_original = scaler.inverse_transform(y_test.numpy())

# Save model
torch.save(model.state_dict(), 'traffic_model.pth')
